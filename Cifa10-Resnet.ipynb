{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\tests\\old\\test_attrs_data.py:251: DeprecationWarning: invalid escape sequence \\H\n",
      "  s = b\"Hello\\x00\\Hello\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\func_inspect.py:53: DeprecationWarning: invalid escape sequence \\<\n",
      "  '\\<doctest (.*\\.rst)\\[(.*)\\]\\>', source_file).groups()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_memory_helpers.py:10: DeprecationWarning: invalid escape sequence \\s\n",
      "  cookie_re = re.compile(\"coding[:=]\\s*([-\\w.]+)\")\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx=mx.gpu()\n",
    "model_ctx=mx.gpu()\n",
    "ctx=mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "def apply_aug_list(img,augs):\n",
    "    for f in augs:\n",
    "        img=f(img)\n",
    "    return img\n",
    "\n",
    "train_augs=[\n",
    "    image.HorizontalFlipAug(0.5),\n",
    "    image.RandomCropAug((28,28))\n",
    "]\n",
    "test_augs=[\n",
    "    image.CenterCropAug((28,28))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\data\\vision\\datasets.py:163: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)\n"
     ]
    }
   ],
   "source": [
    "batch_size =128\n",
    "#num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_examples = 60000\n",
    "def get_transform(augs):\n",
    "    #print('process')\n",
    "    def transform(data, label):\n",
    "        data=data.astype('float32')\n",
    "        print(data.shape)\n",
    "        if augs is not None:\n",
    "            data=nd.stack(*[apply_aug_list(d,augs) for d in data])\n",
    "        data=nd.transpose(data,(0,3,1,2))\n",
    "        print('process')\n",
    "        return data, label.astype(np.float32)\n",
    "    return transform\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.datasets.CIFAR10(train=True, transform=get_transform(train_augs)),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.datasets.CIFAR10(train=False, transform=get_transform(test_augs)),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-b728957e39fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             generator = lambda: [(yield self._batchify_fn([self._dataset[idx] for idx in batch]))\n\u001b[1;32m--> 279\u001b[1;33m                                  for batch in self._batch_sampler]\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             generator = lambda: [(yield self._batchify_fn([self._dataset[idx] for idx in batch]))\n\u001b[0m\u001b[0;32m    279\u001b[0m                                  for batch in self._batch_sampler]\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-a8aec5b66ff0>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(data, label)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapply_aug_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maugs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'process'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-a8aec5b66ff0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapply_aug_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maugs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'process'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-760627f8236e>\u001b[0m in \u001b[0;36mapply_aug_list\u001b[1;34m(img, augs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_aug_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maugs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maugs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\image\\image.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;34m\"\"\"Augmenter body\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrandom_crop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\image\\image.py\u001b[0m in \u001b[0;36mrandom_crop\u001b[1;34m(src, size, interp)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \"\"\"\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m     \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m     \u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_down\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i, (data,label) in enumerate(train_data):\n",
    "    print(data.shape)\n",
    "    break\n",
    "\n",
    "data = data[0:10]\n",
    "fig=plt.figure(0,figsize=(20,5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow((data[i]*255).asnumpy().astype(np.uint8).transpose(0,2,3,1))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fc = 256\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv2D(channels=20, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(gluon.nn.Conv2D(channels=50, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    # The Flatten layer collapses all axis, except the first one, into one axis.\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(num_fc, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_outputs))\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24),ctx=ctx)\n",
    "softmax_cross_entropy=gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ResNets, implemented in Gluon.\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "__all__ = ['ResNetV1', 'ResNetV2',\n",
    "           'BasicBlockV1', 'BasicBlockV2',\n",
    "           'BottleneckV1', 'BottleneckV2',\n",
    "           'resnet18_v1', 'resnet34_v1', 'resnet50_v1', 'resnet101_v1', 'resnet152_v1',\n",
    "           'resnet18_v2', 'resnet34_v2', 'resnet50_v2', 'resnet101_v2', 'resnet152_v2',\n",
    "           'get_resnet']\n",
    "\n",
    "import os\n",
    "from mxnet.gluon.block import HybridBlock\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# Helpers\n",
    "def _conv3x3(channels, stride, in_channels):\n",
    "    return nn.Conv2D(channels, kernel_size=3, strides=stride, padding=1,\n",
    "                     use_bias=False, in_channels=in_channels)\n",
    "\n",
    "\n",
    "# Blocks\n",
    "class BasicBlockV1(HybridBlock):\n",
    "    r\"\"\"BasicBlock V1 from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    This is used for ResNet V1 for 18, 34 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BasicBlockV1, self).__init__(**kwargs)\n",
    "        self.body = nn.HybridSequential(prefix='')\n",
    "        self.body.add(_conv3x3(channels, stride, in_channels))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(_conv3x3(channels, 1, channels))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        if downsample:\n",
    "            self.downsample = nn.HybridSequential(prefix='')\n",
    "            self.downsample.add(nn.Conv2D(channels, kernel_size=1, strides=stride,\n",
    "                                          use_bias=False, in_channels=in_channels))\n",
    "            self.downsample.add(nn.BatchNorm())\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.body(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x = F.Activation(residual+x, act_type='relu')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckV1(HybridBlock):\n",
    "    r\"\"\"Bottleneck V1 from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    This is used for ResNet V1 for 50, 101, 152 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BottleneckV1, self).__init__(**kwargs)\n",
    "        self.body = nn.HybridSequential(prefix='')\n",
    "        self.body.add(nn.Conv2D(channels//4, kernel_size=1, strides=stride))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(_conv3x3(channels//4, 1, channels//4))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(nn.Conv2D(channels, kernel_size=1, strides=1))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        if downsample:\n",
    "            self.downsample = nn.HybridSequential(prefix='')\n",
    "            self.downsample.add(nn.Conv2D(channels, kernel_size=1, strides=stride,\n",
    "                                          use_bias=False, in_channels=in_channels))\n",
    "            self.downsample.add(nn.BatchNorm())\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.body(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x = F.Activation(x + residual, act_type='relu')\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicBlockV2(HybridBlock):\n",
    "    r\"\"\"BasicBlock V2 from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    This is used for ResNet V2 for 18, 34 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BasicBlockV2, self).__init__(**kwargs)\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.conv1 = _conv3x3(channels, stride, in_channels)\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        self.conv2 = _conv3x3(channels, 1, channels)\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2D(channels, 1, stride, use_bias=False,\n",
    "                                        in_channels=in_channels)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "        x = self.bn1(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class BottleneckV2(HybridBlock):\n",
    "    r\"\"\"Bottleneck V2 from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    This is used for ResNet V2 for 50, 101, 152 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BottleneckV2, self).__init__(**kwargs)\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.conv1 = nn.Conv2D(channels//4, kernel_size=1, strides=1, use_bias=False)\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        self.conv2 = _conv3x3(channels//4, stride, channels//4)\n",
    "        self.bn3 = nn.BatchNorm()\n",
    "        self.conv3 = nn.Conv2D(channels, kernel_size=1, strides=1, use_bias=False)\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2D(channels, 1, stride, use_bias=False,\n",
    "                                        in_channels=in_channels)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "        x = self.bn1(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.bn3(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "# Nets\n",
    "class ResNetV1(HybridBlock):\n",
    "    r\"\"\"ResNet V1 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : HybridBlock\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    channels : list of int\n",
    "        Numbers of channels in each block. Length should be one larger than layers list.\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    thumbnail : bool, default False\n",
    "        Enable thumbnail.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, channels, classes=10, thumbnail=False, **kwargs):\n",
    "        super(ResNetV1, self).__init__(**kwargs)\n",
    "        assert len(layers) == len(channels) - 1\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            if thumbnail:\n",
    "                self.features.add(_conv3x3(channels[0], 1, 0))\n",
    "            else:\n",
    "                self.features.add(nn.Conv2D(channels[0], 7, 2, 3, use_bias=False))\n",
    "                self.features.add(nn.BatchNorm())\n",
    "                self.features.add(nn.Activation('relu'))\n",
    "                self.features.add(nn.MaxPool2D(3, 2, 1))\n",
    "\n",
    "            for i, num_layer in enumerate(layers):\n",
    "                stride = 1 if i == 0 else 2\n",
    "                self.features.add(self._make_layer(block, num_layer, channels[i+1],\n",
    "                                                   stride, i+1, in_channels=channels[i]))\n",
    "            self.features.add(nn.GlobalAvgPool2D())\n",
    "\n",
    "            self.output = nn.Dense(classes, in_units=channels[-1])\n",
    "\n",
    "    def _make_layer(self, block, layers, channels, stride, stage_index, in_channels=0):\n",
    "        layer = nn.HybridSequential(prefix='stage%d_'%stage_index)\n",
    "        with layer.name_scope():\n",
    "            layer.add(block(channels, stride, channels != in_channels, in_channels=in_channels,\n",
    "                            prefix=''))\n",
    "            for _ in range(layers-1):\n",
    "                layer.add(block(channels, 1, False, in_channels=channels, prefix=''))\n",
    "        return layer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetV2(HybridBlock):\n",
    "    r\"\"\"ResNet V2 model from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : HybridBlock\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    channels : list of int\n",
    "        Numbers of channels in each block. Length should be one larger than layers list.\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    thumbnail : bool, default False\n",
    "        Enable thumbnail.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, channels, classes=10, thumbnail=False, **kwargs):\n",
    "        super(ResNetV2, self).__init__(**kwargs)\n",
    "        assert len(layers) == len(channels) - 1\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            self.features.add(nn.BatchNorm(scale=False, center=False))\n",
    "            if thumbnail:\n",
    "                self.features.add(_conv3x3(channels[0], 1, 0))\n",
    "            else:\n",
    "                self.features.add(nn.Conv2D(channels[0], 7, 2, 3, use_bias=False))\n",
    "                self.features.add(nn.BatchNorm())\n",
    "                self.features.add(nn.Activation('relu'))\n",
    "                self.features.add(nn.MaxPool2D(3, 2, 1))\n",
    "\n",
    "            in_channels = channels[0]\n",
    "            for i, num_layer in enumerate(layers):\n",
    "                stride = 1 if i == 0 else 2\n",
    "                self.features.add(self._make_layer(block, num_layer, channels[i+1],\n",
    "                                                   stride, i+1, in_channels=in_channels))\n",
    "                in_channels = channels[i+1]\n",
    "            self.features.add(nn.BatchNorm())\n",
    "            self.features.add(nn.Activation('relu'))\n",
    "            self.features.add(nn.GlobalAvgPool2D())\n",
    "            self.features.add(nn.Flatten())\n",
    "\n",
    "            self.output = nn.Dense(classes, in_units=in_channels)\n",
    "\n",
    "    def _make_layer(self, block, layers, channels, stride, stage_index, in_channels=0):\n",
    "        layer = nn.HybridSequential(prefix='stage%d_'%stage_index)\n",
    "        with layer.name_scope():\n",
    "            layer.add(block(channels, stride, channels != in_channels, in_channels=in_channels,\n",
    "                            prefix=''))\n",
    "            for _ in range(layers-1):\n",
    "                layer.add(block(channels, 1, False, in_channels=channels, prefix=''))\n",
    "        return layer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Specification\n",
    "resnet_spec = {18: ('basic_block', [2, 2, 2, 2], [64, 64, 128, 256, 512]),\n",
    "               34: ('basic_block', [3, 4, 6, 3], [64, 64, 128, 256, 512]),\n",
    "               50: ('bottle_neck', [3, 4, 6, 3], [64, 256, 512, 1024, 2048]),\n",
    "               101: ('bottle_neck', [3, 4, 23, 3], [64, 256, 512, 1024, 2048]),\n",
    "               152: ('bottle_neck', [3, 8, 36, 3], [64, 256, 512, 1024, 2048])}\n",
    "\n",
    "resnet_net_versions = [ResNetV1, ResNetV2]\n",
    "resnet_block_versions = [{'basic_block': BasicBlockV1, 'bottle_neck': BottleneckV1},\n",
    "                         {'basic_block': BasicBlockV2, 'bottle_neck': BottleneckV2}]\n",
    "\n",
    "\n",
    "# Constructor\n",
    "def get_resnet(version, num_layers, pretrained=False, ctx=ctx,\n",
    "               root=os.path.join('~', '.mxnet', 'models'), **kwargs):\n",
    "    r\"\"\"ResNet V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    ResNet V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    version : int\n",
    "        Version of ResNet. Options are 1, 2.\n",
    "    num_layers : int\n",
    "        Numbers of layers. Options are 18, 34, 50, 101, 152.\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    block_type, layers, channels = resnet_spec[num_layers]\n",
    "    resnet_class = resnet_net_versions[version-1]\n",
    "    block_class = resnet_block_versions[version-1][block_type]\n",
    "    net = resnet_class(block_class, layers, channels, **kwargs)\n",
    "    if pretrained:\n",
    "        from ..model_store import get_model_file\n",
    "        net.load_params(get_model_file('resnet%d_v%d'%(num_layers, version),\n",
    "                                       root=root), ctx=ctx)\n",
    "    return net\n",
    "\n",
    "def resnet18_v1(**kwargs):\n",
    "    r\"\"\"ResNet-18 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 18, **kwargs)\n",
    "\n",
    "def resnet34_v1(**kwargs):\n",
    "    r\"\"\"ResNet-34 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 34, **kwargs)\n",
    "\n",
    "def resnet50_v1(**kwargs):\n",
    "    r\"\"\"ResNet-50 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 50, **kwargs)\n",
    "\n",
    "def resnet101_v1(**kwargs):\n",
    "    r\"\"\"ResNet-101 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 101, **kwargs)\n",
    "\n",
    "def resnet152_v1(**kwargs):\n",
    "    r\"\"\"ResNet-152 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 152, **kwargs)\n",
    "\n",
    "def resnet18_v2(**kwargs):\n",
    "    r\"\"\"ResNet-18 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 18, **kwargs)\n",
    "\n",
    "def resnet34_v2(**kwargs):\n",
    "    r\"\"\"ResNet-34 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 34, **kwargs)\n",
    "\n",
    "def resnet50_v2(**kwargs):\n",
    "    r\"\"\"ResNet-50 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 50, **kwargs)\n",
    "\n",
    "def resnet101_v2(**kwargs):\n",
    "    r\"\"\"ResNet-101 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 101, **kwargs)\n",
    "\n",
    "def resnet152_v2(**kwargs):\n",
    "    r\"\"\"ResNet-152 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 152, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=get_resnet(2,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(),ctx=ctx)\n",
    "softmax_cross_entropy=gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator,net):\n",
    "    acc=mx.metric.Accuracy()\n",
    "    for i, (data,label) in enumerate(data_iterator):\n",
    "        data=data.as_in_context(ctx)\n",
    "        label=label.as_in_context(ctx)\n",
    "        output=net(data)\n",
    "        predictions=nd.argmax(output,axis=1)\n",
    "        #print(predictions)\n",
    "        #print(label)\n",
    "        acc.update(preds=predictions,labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.4093958310585072, Train_acc 0.8952, Test_acc 0.6993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c9d3ef9ce5a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m##########################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\trainer.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, batch_size, ignore_stale_grad)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mupd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_updaters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_stale_grad\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fresh_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                     \u001b[0mupd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                     \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fresh_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\optimizer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, index, grad, weight)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_state_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates_synced\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_multi_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msync_state_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\optimizer.py\u001b[0m in \u001b[0;36mupdate_multi_precision\u001b[1;34m(self, index, weight, grad, state)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0muse_multi_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_precision\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         self._update_impl(index, weight, grad, state,\n\u001b[1;32m--> 535\u001b[1;33m                           multi_precision=use_multi_precision)\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\optimizer.py\u001b[0m in \u001b[0;36m_update_impl\u001b[1;34m(self, index, weight, grad, state, multi_precision)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m                 sgd_update(weight, grad, out=weight,\n\u001b[1;32m--> 520\u001b[1;33m                            lr=lr, wd=wd, **kwargs)\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\ndarray\\register.py\u001b[0m in \u001b[0;36msgd_update\u001b[1;34m(weight, grad, lr, wd, rescale_grad, clip_gradient, out, name, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[1;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
