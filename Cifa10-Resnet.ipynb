{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\tests\\old\\test_attrs_data.py:251: DeprecationWarning: invalid escape sequence \\H\n",
      "  s = b\"Hello\\x00\\Hello\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\func_inspect.py:53: DeprecationWarning: invalid escape sequence \\<\n",
      "  '\\<doctest (.*\\.rst)\\[(.*)\\]\\>', source_file).groups()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_memory_helpers.py:10: DeprecationWarning: invalid escape sequence \\s\n",
      "  cookie_re = re.compile(\"coding[:=]\\s*([-\\w.]+)\")\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx=mx.gpu()\n",
    "model_ctx=mx.gpu()\n",
    "ctx=mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import image\n",
    "def apply_aug_list(img,augs):\n",
    "    #print(img.shape)\n",
    "    for f in augs:\n",
    "        img=f(img)\n",
    "    return img\n",
    "\n",
    "train_augs=[\n",
    "    image.HorizontalFlipAug(0.5),\n",
    "    image.RandomCropAug((28,28))\n",
    "]\n",
    "test_augs=[\n",
    "    image.CenterCropAug((28,28))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mxnet\\gluon\\data\\vision\\datasets.py:163: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)\n"
     ]
    }
   ],
   "source": [
    "batch_size =128\n",
    "#num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_examples = 60000\n",
    "def get_transform(augs):\n",
    "    #print('process')\n",
    "    def transform(data, label):\n",
    "        data=data.astype('float32')\n",
    "        #print(data.shape)\n",
    "        if augs is not None:\n",
    "            data=apply_aug_list(data,augs)\n",
    "        #print(data.shape)\n",
    "        data=nd.transpose(data,(2,0,1))/255\n",
    "        #print('process')\n",
    "        return data, label.astype(np.float32)\n",
    "    return transform\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.datasets.CIFAR10(train=True, transform=get_transform(train_augs)),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.datasets.CIFAR10(train=False, transform=get_transform(test_augs)),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 3, 28, 28)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.transpose(data.astype(np.float32), (2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233af02c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i, (data,label) in enumerate(train_data):\n",
    "    print(data.shape)\n",
    "    break\n",
    "\n",
    "data = data[0:10]\n",
    "fig=plt.figure(0,figsize=(20,5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow((data[i]*255).asnumpy().astype(np.uint8).transpose(1,2,0))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fc = 256\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv2D(channels=20, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(gluon.nn.Conv2D(channels=50, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    # The Flatten layer collapses all axis, except the first one, into one axis.\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(num_fc, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_outputs))\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24),ctx=ctx)\n",
    "softmax_cross_entropy=gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ResNets, implemented in Gluon.\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "__all__ = ['ResNetV1', 'ResNetV2',\n",
    "           'BasicBlockV1', 'BasicBlockV2',\n",
    "           'BottleneckV1', 'BottleneckV2',\n",
    "           'resnet18_v1', 'resnet34_v1', 'resnet50_v1', 'resnet101_v1', 'resnet152_v1',\n",
    "           'resnet18_v2', 'resnet34_v2', 'resnet50_v2', 'resnet101_v2', 'resnet152_v2',\n",
    "           'get_resnet']\n",
    "\n",
    "import os\n",
    "from mxnet.gluon.block import HybridBlock\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# Helpers\n",
    "def _conv3x3(channels, stride, in_channels):\n",
    "    return nn.Conv2D(channels, kernel_size=3, strides=stride, padding=1,\n",
    "                     use_bias=False, in_channels=in_channels)\n",
    "\n",
    "\n",
    "# Blocks\n",
    "class BasicBlockV1(HybridBlock):\n",
    "    r\"\"\"BasicBlock V1 from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    This is used for ResNet V1 for 18, 34 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BasicBlockV1, self).__init__(**kwargs)\n",
    "        self.body = nn.HybridSequential(prefix='')\n",
    "        self.body.add(_conv3x3(channels, stride, in_channels))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(_conv3x3(channels, 1, channels))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        if downsample:\n",
    "            self.downsample = nn.HybridSequential(prefix='')\n",
    "            self.downsample.add(nn.Conv2D(channels, kernel_size=1, strides=stride,\n",
    "                                          use_bias=False, in_channels=in_channels))\n",
    "            self.downsample.add(nn.BatchNorm())\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.body(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x = F.Activation(residual+x, act_type='relu')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckV1(HybridBlock):\n",
    "    r\"\"\"Bottleneck V1 from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    This is used for ResNet V1 for 50, 101, 152 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BottleneckV1, self).__init__(**kwargs)\n",
    "        self.body = nn.HybridSequential(prefix='')\n",
    "        self.body.add(nn.Conv2D(channels//4, kernel_size=1, strides=stride))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(_conv3x3(channels//4, 1, channels//4))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        self.body.add(nn.Conv2D(channels, kernel_size=1, strides=1))\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        if downsample:\n",
    "            self.downsample = nn.HybridSequential(prefix='')\n",
    "            self.downsample.add(nn.Conv2D(channels, kernel_size=1, strides=stride,\n",
    "                                          use_bias=False, in_channels=in_channels))\n",
    "            self.downsample.add(nn.BatchNorm())\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.body(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x = F.Activation(x + residual, act_type='relu')\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicBlockV2(HybridBlock):\n",
    "    r\"\"\"BasicBlock V2 from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    This is used for ResNet V2 for 18, 34 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BasicBlockV2, self).__init__(**kwargs)\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.conv1 = _conv3x3(channels, stride, in_channels)\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        self.conv2 = _conv3x3(channels, 1, channels)\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2D(channels, 1, stride, use_bias=False,\n",
    "                                        in_channels=in_channels)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "        x = self.bn1(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class BottleneckV2(HybridBlock):\n",
    "    r\"\"\"Bottleneck V2 from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    This is used for ResNet V2 for 50, 101, 152 layers.\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, downsample=False, in_channels=0, **kwargs):\n",
    "        super(BottleneckV2, self).__init__(**kwargs)\n",
    "        self.bn1 = nn.BatchNorm()\n",
    "        self.conv1 = nn.Conv2D(channels//4, kernel_size=1, strides=1, use_bias=False)\n",
    "        self.bn2 = nn.BatchNorm()\n",
    "        self.conv2 = _conv3x3(channels//4, stride, channels//4)\n",
    "        self.bn3 = nn.BatchNorm()\n",
    "        self.conv3 = nn.Conv2D(channels, kernel_size=1, strides=1, use_bias=False)\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2D(channels, 1, stride, use_bias=False,\n",
    "                                        in_channels=in_channels)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "        x = self.bn1(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.bn3(x)\n",
    "        x = F.Activation(x, act_type='relu')\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "# Nets\n",
    "class ResNetV1(HybridBlock):\n",
    "    r\"\"\"ResNet V1 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : HybridBlock\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    channels : list of int\n",
    "        Numbers of channels in each block. Length should be one larger than layers list.\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    thumbnail : bool, default False\n",
    "        Enable thumbnail.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, channels, classes=10, thumbnail=False, **kwargs):\n",
    "        super(ResNetV1, self).__init__(**kwargs)\n",
    "        assert len(layers) == len(channels) - 1\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            if thumbnail:\n",
    "                self.features.add(_conv3x3(channels[0], 1, 0))\n",
    "            else:\n",
    "                self.features.add(nn.Conv2D(channels[0], 7, 2, 3, use_bias=False))\n",
    "                self.features.add(nn.BatchNorm())\n",
    "                self.features.add(nn.Activation('relu'))\n",
    "                self.features.add(nn.MaxPool2D(3, 2, 1))\n",
    "\n",
    "            for i, num_layer in enumerate(layers):\n",
    "                stride = 1 if i == 0 else 2\n",
    "                self.features.add(self._make_layer(block, num_layer, channels[i+1],\n",
    "                                                   stride, i+1, in_channels=channels[i]))\n",
    "            self.features.add(nn.GlobalAvgPool2D())\n",
    "\n",
    "            self.output = nn.Dense(classes, in_units=channels[-1])\n",
    "\n",
    "    def _make_layer(self, block, layers, channels, stride, stage_index, in_channels=0):\n",
    "        layer = nn.HybridSequential(prefix='stage%d_'%stage_index)\n",
    "        with layer.name_scope():\n",
    "            layer.add(block(channels, stride, channels != in_channels, in_channels=in_channels,\n",
    "                            prefix=''))\n",
    "            for _ in range(layers-1):\n",
    "                layer.add(block(channels, 1, False, in_channels=channels, prefix=''))\n",
    "        return layer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetV2(HybridBlock):\n",
    "    r\"\"\"ResNet V2 model from\n",
    "    `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : HybridBlock\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    channels : list of int\n",
    "        Numbers of channels in each block. Length should be one larger than layers list.\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    thumbnail : bool, default False\n",
    "        Enable thumbnail.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, channels, classes=10, thumbnail=False, **kwargs):\n",
    "        super(ResNetV2, self).__init__(**kwargs)\n",
    "        assert len(layers) == len(channels) - 1\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            self.features.add(nn.BatchNorm(scale=False, center=False))\n",
    "            if thumbnail:\n",
    "                self.features.add(_conv3x3(channels[0], 1, 0))\n",
    "            else:\n",
    "                self.features.add(nn.Conv2D(channels[0], 7, 2, 3, use_bias=False))\n",
    "                self.features.add(nn.BatchNorm())\n",
    "                self.features.add(nn.Activation('relu'))\n",
    "                self.features.add(nn.MaxPool2D(3, 2, 1))\n",
    "\n",
    "            in_channels = channels[0]\n",
    "            for i, num_layer in enumerate(layers):\n",
    "                stride = 1 if i == 0 else 2\n",
    "                self.features.add(self._make_layer(block, num_layer, channels[i+1],\n",
    "                                                   stride, i+1, in_channels=in_channels))\n",
    "                in_channels = channels[i+1]\n",
    "            self.features.add(nn.BatchNorm())\n",
    "            self.features.add(nn.Activation('relu'))\n",
    "            self.features.add(nn.GlobalAvgPool2D())\n",
    "            self.features.add(nn.Flatten())\n",
    "\n",
    "            self.output = nn.Dense(classes, in_units=in_channels)\n",
    "\n",
    "    def _make_layer(self, block, layers, channels, stride, stage_index, in_channels=0):\n",
    "        layer = nn.HybridSequential(prefix='stage%d_'%stage_index)\n",
    "        with layer.name_scope():\n",
    "            layer.add(block(channels, stride, channels != in_channels, in_channels=in_channels,\n",
    "                            prefix=''))\n",
    "            for _ in range(layers-1):\n",
    "                layer.add(block(channels, 1, False, in_channels=channels, prefix=''))\n",
    "        return layer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Specification\n",
    "resnet_spec = {18: ('basic_block', [2, 2, 2, 2], [64, 64, 128, 256, 512]),\n",
    "               34: ('basic_block', [3, 4, 6, 3], [64, 64, 128, 256, 512]),\n",
    "               50: ('bottle_neck', [3, 4, 6, 3], [64, 256, 512, 1024, 2048]),\n",
    "               101: ('bottle_neck', [3, 4, 23, 3], [64, 256, 512, 1024, 2048]),\n",
    "               152: ('bottle_neck', [3, 8, 36, 3], [64, 256, 512, 1024, 2048])}\n",
    "\n",
    "resnet_net_versions = [ResNetV1, ResNetV2]\n",
    "resnet_block_versions = [{'basic_block': BasicBlockV1, 'bottle_neck': BottleneckV1},\n",
    "                         {'basic_block': BasicBlockV2, 'bottle_neck': BottleneckV2}]\n",
    "\n",
    "\n",
    "# Constructor\n",
    "def get_resnet(version, num_layers, pretrained=False, ctx=ctx,\n",
    "               root=os.path.join('~', '.mxnet', 'models'), **kwargs):\n",
    "    r\"\"\"ResNet V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    ResNet V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    version : int\n",
    "        Version of ResNet. Options are 1, 2.\n",
    "    num_layers : int\n",
    "        Numbers of layers. Options are 18, 34, 50, 101, 152.\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    block_type, layers, channels = resnet_spec[num_layers]\n",
    "    resnet_class = resnet_net_versions[version-1]\n",
    "    block_class = resnet_block_versions[version-1][block_type]\n",
    "    net = resnet_class(block_class, layers, channels, **kwargs)\n",
    "    if pretrained:\n",
    "        from ..model_store import get_model_file\n",
    "        net.load_params(get_model_file('resnet%d_v%d'%(num_layers, version),\n",
    "                                       root=root), ctx=ctx)\n",
    "    return net\n",
    "\n",
    "def resnet18_v1(**kwargs):\n",
    "    r\"\"\"ResNet-18 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 18, **kwargs)\n",
    "\n",
    "def resnet34_v1(**kwargs):\n",
    "    r\"\"\"ResNet-34 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 34, **kwargs)\n",
    "\n",
    "def resnet50_v1(**kwargs):\n",
    "    r\"\"\"ResNet-50 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 50, **kwargs)\n",
    "\n",
    "def resnet101_v1(**kwargs):\n",
    "    r\"\"\"ResNet-101 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 101, **kwargs)\n",
    "\n",
    "def resnet152_v1(**kwargs):\n",
    "    r\"\"\"ResNet-152 V1 model from `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(1, 152, **kwargs)\n",
    "\n",
    "def resnet18_v2(**kwargs):\n",
    "    r\"\"\"ResNet-18 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 18, **kwargs)\n",
    "\n",
    "def resnet34_v2(**kwargs):\n",
    "    r\"\"\"ResNet-34 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 34, **kwargs)\n",
    "\n",
    "def resnet50_v2(**kwargs):\n",
    "    r\"\"\"ResNet-50 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 50, **kwargs)\n",
    "\n",
    "def resnet101_v2(**kwargs):\n",
    "    r\"\"\"ResNet-101 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 101, **kwargs)\n",
    "\n",
    "def resnet152_v2(**kwargs):\n",
    "    r\"\"\"ResNet-152 V2 model from `\"Identity Mappings in Deep Residual Networks\"\n",
    "    <https://arxiv.org/abs/1603.05027>`_ paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(2, 152, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=get_resnet(2,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Xavier(),ctx=ctx)\n",
    "softmax_cross_entropy=gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer=gluon.Trainer(net.collect_params(),'Adam',{'learning_rate':.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator,net):\n",
    "    acc=mx.metric.Accuracy()\n",
    "    for i, (data,label) in enumerate(data_iterator):\n",
    "        data=data.as_in_context(ctx)\n",
    "        label=label.as_in_context(ctx)\n",
    "        output=net(data)\n",
    "        predictions=nd.argmax(output,axis=1)\n",
    "        #print(predictions)\n",
    "        #print(label)\n",
    "        acc.update(preds=predictions,labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.363651871579075, Train_acc 0.88314, Test_acc 0.8096\n",
      "Epoch 1. Loss: 0.35223225745546766, Train_acc 0.88598, Test_acc 0.8161\n",
      "Epoch 2. Loss: 0.33767221348424836, Train_acc 0.89202, Test_acc 0.8149\n",
      "Epoch 3. Loss: 0.33258445678798704, Train_acc 0.89108, Test_acc 0.8073\n",
      "Epoch 4. Loss: 0.32117364624387496, Train_acc 0.89924, Test_acc 0.8158\n",
      "Epoch 5. Loss: 0.3249049955202747, Train_acc 0.91216, Test_acc 0.8257\n",
      "Epoch 6. Loss: 0.30945982444202574, Train_acc 0.89878, Test_acc 0.8128\n",
      "Epoch 7. Loss: 0.29610876176019346, Train_acc 0.91134, Test_acc 0.8186\n",
      "Epoch 8. Loss: 0.299500419496796, Train_acc 0.90672, Test_acc 0.8198\n",
      "Epoch 9. Loss: 0.28412970705596363, Train_acc 0.9058, Test_acc 0.8153\n",
      "Epoch 10. Loss: 0.2875151780285442, Train_acc 0.9197, Test_acc 0.8192\n",
      "Epoch 11. Loss: 0.27679281179087273, Train_acc 0.91626, Test_acc 0.8204\n",
      "Epoch 12. Loss: 0.2645471108971061, Train_acc 0.92068, Test_acc 0.8236\n",
      "Epoch 13. Loss: 0.26542953755690657, Train_acc 0.92278, Test_acc 0.8201\n",
      "Epoch 14. Loss: 0.254556417410156, Train_acc 0.93002, Test_acc 0.8241\n",
      "Epoch 15. Loss: 0.2508307470628239, Train_acc 0.91754, Test_acc 0.8103\n",
      "Epoch 16. Loss: 0.25075473991870056, Train_acc 0.92086, Test_acc 0.8153\n",
      "Epoch 17. Loss: 0.2442104424689157, Train_acc 0.9233, Test_acc 0.8248\n",
      "Epoch 18. Loss: 0.23654621611377277, Train_acc 0.92952, Test_acc 0.8218\n",
      "Epoch 19. Loss: 0.23692032771919522, Train_acc 0.93134, Test_acc 0.8214\n",
      "Epoch 20. Loss: 0.21827337594380494, Train_acc 0.93394, Test_acc 0.8263\n",
      "Epoch 21. Loss: 0.21758664172673686, Train_acc 0.93084, Test_acc 0.8226\n",
      "Epoch 22. Loss: 0.21928328543425737, Train_acc 0.93036, Test_acc 0.8235\n",
      "Epoch 23. Loss: 0.20740644920792708, Train_acc 0.9376, Test_acc 0.8296\n",
      "Epoch 24. Loss: 0.19833864158835332, Train_acc 0.94066, Test_acc 0.8263\n",
      "Epoch 25. Loss: 0.20584841469300805, Train_acc 0.94, Test_acc 0.8264\n",
      "Epoch 26. Loss: 0.19845043982464214, Train_acc 0.93246, Test_acc 0.8193\n",
      "Epoch 27. Loss: 0.1946746634352866, Train_acc 0.94366, Test_acc 0.8226\n",
      "Epoch 28. Loss: 0.1996592781297687, Train_acc 0.94444, Test_acc 0.8244\n",
      "Epoch 29. Loss: 0.18085225920717948, Train_acc 0.9431, Test_acc 0.8221\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
